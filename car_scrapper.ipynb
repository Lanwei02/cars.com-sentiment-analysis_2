{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(url):\n",
    "    car_url=requests.get(url)\n",
    "    while str(car_url) == '<Response [503]>':\n",
    "        url = next_page(url)\n",
    "        car_url=requests.get(url)\n",
    "    return car_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrap_rate2(url):\n",
    "    #car_url=requests.get(url)\n",
    "    car_url = test(url)\n",
    "    car_soup = bs4.BeautifulSoup(car_url.text,'lxml')\n",
    "    #get rate\n",
    "    rate_all = car_soup.select('article cars-star-rating')\n",
    "    stars=[i.text[0] for i in rate_all[0::7]]\n",
    "    return stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrap_rate(url):\n",
    "    car_url=requests.get(url)\n",
    "    car_soup = bs4.BeautifulSoup(car_url.text,'lxml')\n",
    "    #get rate\n",
    "    rate_all = car_soup.select('article cars-star-rating')\n",
    "    stars=[i.text[0] for i in rate_all[0::7]]\n",
    "    return stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrap_review(url):\n",
    "    car_url=requests.get(url)\n",
    "    car_soup = bs4.BeautifulSoup(car_url.text,'lxml')\n",
    "    #get review\n",
    "    review = car_soup.select('p.review-card-text')\n",
    "    review=[i.text.rstrip()[2:-2].lstrip() for i in review]\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def scrap_reviewTime(url):\n",
    "    car_url=requests.get(url)\n",
    "    car_soup = bs4.BeautifulSoup(car_url.text,'lxml')\n",
    "    #get review_time\n",
    "    review_time = car_soup.select('p.review-card-review-by')\n",
    "    review_time=[i.text.split('\\n')[-2].lstrip()[3:] for i in review_time]\n",
    "    review_time=[datetime.strptime(i, '%B %d, %Y') for i in review_time]\n",
    "    return review_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrap_reviewArea(url):\n",
    "    car_url=requests.get(url)\n",
    "    car_soup = bs4.BeautifulSoup(car_url.text,'lxml')\n",
    "    #get area\n",
    "    review_city = car_soup.select('p.review-card-review-by')\n",
    "    review_city = [i.text.split('\\n')[-3].lstrip()[5:] for i in review_city]\n",
    "    return review_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_page(url):\n",
    "    car_url=requests.get(url)\n",
    "    car_soup = bs4.BeautifulSoup(car_url.text,'lxml')\n",
    "    #get tag\n",
    "    links = car_soup.find_all(\"a\", class_=\"cui-button cui-button--secondary\")\n",
    "    if links==[]:\n",
    "        # Last Page\n",
    "        return 'This is the last page'\n",
    "    elif len(links)==1:\n",
    "        # The next page of the first page\n",
    "        next_links=links[0].get('href')\n",
    "        next_links='https://www.cars.com'+next_links\n",
    "        return next_links\n",
    "    else:\n",
    "        # Normal next page\n",
    "        next_links=links[1].get('href')\n",
    "        next_links='https://www.cars.com'+next_links\n",
    "        return next_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrap(make, model, year=['2018']):\n",
    "    rate = []\n",
    "    for i in year:\n",
    "        url='https://www.cars.com/research/'+make+'-'+model+'-'+i+'/consumer-reviews/'\n",
    "        print('first page '+url)\n",
    "        rate.extend(scrap_rate(url))\n",
    "        print(rate)\n",
    "        next_url = next_page(url)\n",
    "        print('second page '+next_url)\n",
    "        while next_url != 'This is the last page':\n",
    "            print('1 '+next_url)\n",
    "            new_rate = scrap_rate(next_url)\n",
    "            print(new_rate)\n",
    "            rate.extend(new_rate)\n",
    "            next_url = next_page(next_url)\n",
    "            print('2 '+next_url)\n",
    "    print(rate)\n",
    "    return rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrap('chevrolet', 'camaro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
